{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PolyGen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3mfGYv7VDXPuNN/6E7kJ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jake-Baum/model-gen/blob/main/PolyGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "qpUhG0VL7Zqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GNoOn0VCf1W1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and unzip files"
      ],
      "metadata": {
        "id": "m5HC80AM7b2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip(readPath, writePath):\n",
        "    with zipfile.ZipFile(readPath, 'r') as zip_ref:\n",
        "        zip_ref.extractall(writePath)\n",
        "\n",
        "url = 'https://masonmcgough-data-bucket.s3-us-west-2.amazonaws.com/ShapeNetCore_PolyGenSubset.zip'\n",
        "\n",
        "urllib.request.urlretrieve(url, 'dataset.zip')\n",
        "unzip('dataset.zip', 'dataset')\n",
        "\n",
        "os.listdir('dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owdv5UnbgPG5",
        "outputId": "85e0c979-95a0-41a7-e605-c8aab3a969ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'val']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create method for loading objects from file into array of vertices.\n",
        "Then a chair model is loaded"
      ],
      "metadata": {
        "id": "KigCrhXMJtIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadObject(filename):\n",
        "  vertices = []\n",
        "  with open(filename, 'r') as mesh:\n",
        "    for line in mesh:\n",
        "      data = line.split()\n",
        "      if len(data) > 0 and data[0] == 'v':\n",
        "        vertices.append(data[1:])\n",
        "  return np.array(vertices, dtype=np.float32)\n",
        "\n",
        "verts = loadObject('dataset/train/chair/model_012429-0001.obj')\n",
        "vertsKeys = [verts[..., i] for i in range(verts.shape[-1])]\n",
        "sortIdxs = np.lexsort(vertsKeys)\n",
        "vertsSorted = verts[sortIdxs]"
      ],
      "metadata": {
        "id": "hoWCRsJn7Jjd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalise (-1.0 - 1.0) and quantise (0, 255) vertices."
      ],
      "metadata": {
        "id": "hOdMKgPIJo9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "limits = [-1.0, 1.0]\n",
        "normVerts = (verts - limits[0]) / (limits[1] - limits[0])\n",
        "\n",
        "nVals = 2 ** 8\n",
        "delta = 1. / nVals\n",
        "quantVerts = np.maximum(np.minimum((normVerts // delta), nVals - 1), 0).astype(np.int32)"
      ],
      "metadata": {
        "id": "P6quwjfUJdca"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V7iprbdKLKmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENS = {\n",
        "    '<pad>': 0,\n",
        "    '<sos>': 1,\n",
        "    '<eos>': 2\n",
        "}\n",
        "\n",
        "maxVerts = 12\n",
        "maxSeqLen = 3 * maxVerts + 2 # number of coords + start and stop tokens\n",
        "nTokens = len(TOKENS)\n",
        "seqLen = len(quantVerts) + 2\n",
        "nPadding = maxSeqLen - seqLen\n",
        "\n",
        "valTokens = np.concatenate((\n",
        "    [TOKENS['<sos>']],\n",
        "    quantVerts + nTokens,\n",
        "    [TOKENS['<eos>']],\n",
        "    nPadding * [TOKENS['<pad>']]\n",
        "))\n",
        "\n",
        "coordTokens = np.concatenate(([0], np.arrange(len(quantVerts)) % 3 + 1, (nPadding + 1) * [0]))\n",
        "posTokens = np.arrange(len(quantTokens), dtype=np.int32)"
      ],
      "metadata": {
        "id": "N9MRdN-_LNgb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}