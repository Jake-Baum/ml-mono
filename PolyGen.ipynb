{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PolyGen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMOFp7pEWfF6Z7Y2BjCRSFH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jake-Baum/model-gen/blob/main/PolyGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "qpUhG0VL7Zqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "GNoOn0VCf1W1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and unzip files\n",
        "\n",
        "Pulling in a pre-decimated subset of the ShapeNetCore data set."
      ],
      "metadata": {
        "id": "m5HC80AM7b2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip(readPath, writePath):\n",
        "    with zipfile.ZipFile(readPath, 'r') as zip_ref:\n",
        "        zip_ref.extractall(writePath)\n",
        "\n",
        "url = 'https://masonmcgough-data-bucket.s3-us-west-2.amazonaws.com/ShapeNetCore_PolyGenSubset.zip'\n",
        "\n",
        "urllib.request.urlretrieve(url, 'dataset.zip')\n",
        "unzip('dataset.zip', 'dataset')\n",
        "\n",
        "urllib.request.urlretrieve('https://masonmcgough-data-bucket.s3-us-west-2.amazonaws.com/cube.obj', 'cube.obj')\n",
        "\n",
        "os.listdir('.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owdv5UnbgPG5",
        "outputId": "89171a02-7af0-4ddf-e12a-0a2c0174d311"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'cube.obj', 'dataset', 'dataset.zip', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create method for loading objects from file into array of vertices.\n",
        "\n",
        "A simple cube model is loaded"
      ],
      "metadata": {
        "id": "KigCrhXMJtIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadObject(filename):\n",
        "  vertices = []\n",
        "  with open(filename, 'r') as mesh:\n",
        "    for line in mesh:\n",
        "      data = line.split()\n",
        "      if len(data) > 0 and data[0] == 'v':\n",
        "        vertices.append(data[1:])\n",
        "  return np.array(vertices, dtype=np.float32)\n",
        "\n",
        "verts = loadObject('cube.obj')\n",
        "#verts = loadObject('dataset/train/chair/model_012429-0001.obj')"
      ],
      "metadata": {
        "id": "hoWCRsJn7Jjd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort the vertices, in ascending order, z axis first, then y, then x"
      ],
      "metadata": {
        "id": "QJ6iBucY5Cbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vertsKeys = [verts[..., i] for i in range(verts.shape[-1])]\n",
        "sortIdxs = np.lexsort(vertsKeys)\n",
        "vertsSorted = verts[sortIdxs]\n",
        "flattenedVerts = [coord for vert in vertsSorted for coord in vert]\n",
        "flattenedVerts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t6jCRlu5CvA",
        "outputId": "254d5983-ae6d-4eb1-8bc5-7c6745da139e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1.0,\n",
              " -1.0,\n",
              " -1.0,\n",
              " 1.0,\n",
              " -1.0,\n",
              " -1.0,\n",
              " -1.0,\n",
              " 1.0,\n",
              " -1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " -1.0,\n",
              " -1.0,\n",
              " -1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " -1.0,\n",
              " 1.0,\n",
              " -1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalise (-1.0 - 1.0) and quantise (0, 255) vertices."
      ],
      "metadata": {
        "id": "hOdMKgPIJo9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normVerts = [(i - min(flattenedVerts)) / (max(flattenedVerts) - min(flattenedVerts)) for i in flattenedVerts]\n",
        "\n",
        "nBits = 8\n",
        "nVals = 2 ** nBits\n",
        "delta = 1.0 / nVals\n",
        "quantVerts = np.maximum(np.minimum([i // delta for i in normVerts], nVals - 1), 0).astype(np.int32)\n",
        "quantVerts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6quwjfUJdca",
        "outputId": "98c1bf13-8812-4e49-eb05-8c76a5c2aea8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0, 255,   0,   0,   0, 255,   0, 255, 255,   0,   0,\n",
              "         0, 255, 255,   0, 255,   0, 255, 255, 255, 255, 255], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create tokens.  There are 3 sets of tokens:\n",
        " - The value tokens, which is the start token, followed by the quantised vertices (with the number of tokens added to the value, such that they do not overlap), then the end token, followed by any padding tokens.\n",
        " - The coordinate tokens, which label the value tokens with the coordinate index, 1 for x, 2 for y and 3 for z.\n",
        " - The position tokens, which is simply a number range of equal length to the previous lists."
      ],
      "metadata": {
        "id": "V7iprbdKLKmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENS = {\n",
        "    '<pad>': 0,\n",
        "    '<sos>': 1,\n",
        "    '<eos>': 2\n",
        "}\n",
        "\n",
        "maxVerts = 12\n",
        "maxSeqLen = 3 * maxVerts + 2 # number of coords + start and stop tokens\n",
        "nTokens = len(TOKENS)\n",
        "seqLen = len(quantVerts) + 2\n",
        "nPadding = maxSeqLen - seqLen\n",
        "\n",
        "coordTokens = np.concatenate(([0], np.arange(len(quantVerts)) % 3 + 1, (nPadding + 1) * [0]))\n",
        "print(coordTokens, len(coordTokens))\n",
        "\n",
        "valTokens = np.concatenate((\n",
        "    [TOKENS['<sos>']],\n",
        "    quantVerts + nTokens,\n",
        "    [TOKENS['<eos>']],\n",
        "    nPadding * [TOKENS['<pad>']]\n",
        "))\n",
        "print(valTokens, len(valTokens))\n",
        "\n",
        "posTokens = np.arange(len(coordTokens), dtype=np.int32)\n",
        "posTokens"
      ],
      "metadata": {
        "id": "N9MRdN-_LNgb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b94ccbeb-f3ea-4fae-b1e8-9d4769f0d6bc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0] 38\n",
            "[  1   3   3   3 258   3   3   3 258   3 258 258   3   3   3 258 258   3\n",
            " 258   3 258 258 258 258 258   2   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0] 38\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create embedding layers for each set of tokens and sum them to create a single one."
      ],
      "metadata": {
        "id": "AroohssnC-Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nEmbeddingChannels = 256\n",
        "\n",
        "nEmbeddingsValue = 2 ** nBits + nTokens\n",
        "valueEmbedding = tf.keras.layers.Embedding(nEmbeddingsValue, nEmbeddingChannels, input_length=1)\n",
        "\n",
        "nEmbeddingsCoord = 4\n",
        "coordEmbedding = tf.keras.layers.Embedding(nEmbeddingsCoord, nEmbeddingChannels)\n",
        "\n",
        "nEmbeddingsPos = maxSeqLen\n",
        "posEmbedding = tf.keras.layers.Embedding(nEmbeddingsPos, nEmbeddingChannels)\n",
        "\n",
        "\n",
        "#valueEmbed = valueEmbedding(valTokens)\n",
        "#coordEmbed = coordEmbedding(coordTokens)\n",
        "#posEmbed = posEmbedding(posTokens)\n",
        "\n",
        "x = valueEmbedding + coordEmbedding + posEmbedding\n",
        "x"
      ],
      "metadata": {
        "id": "ZveuvdZsgEbC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "a736ebd5-5f49-4ee9-97e9-1a291b32350b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-0ebabcfff32f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#posEmbed = posEmbedding(posTokens)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalueEmbedding\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcoordEmbedding\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Embedding' and 'Embedding'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IiBb-nWMDM_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = tf.keras.layers.Dense(maxSeqLen, tf.nn.softmax)\n",
        "model = tf.keras.Model(x, output)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "_KQ-wQuRPjgL",
        "outputId": "9036cd17-428d-4aa2-ad9a-4dade1a12a1a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-468ab55f4d5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxSeqLen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       if not all([functional_utils.is_input_keras_tensor(t)\n\u001b[0;32m--> 144\u001b[0;31m                   for t in tf.nest.flatten(inputs)]):\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       if not all([functional_utils.is_input_keras_tensor(t)\n\u001b[0;32m--> 144\u001b[0;31m                   for t in tf.nest.flatten(inputs)]):\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional_utils.py\u001b[0m in \u001b[0;36mis_input_keras_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     45\u001b[0m   \"\"\"\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: [[-0.01889815 -0.00035994 -0.04725806 ...  0.01974867 -0.08538379\n   0.01886638]\n [-0.00165155  0.02091495 -0.04873869 ...  0.03017981 -0.02233417\n   0.11752406]\n [-0.03759596 -0.00034427  0.00445802 ... -0.01057025  0.02424473\n   0.03414505]\n ...\n [ 0.03001543  0.02064419  0.02652806 ...  0.0246079  -0.01208412\n  -0.02835017]\n [-0.0148664  -0.02187714 -0.03222066 ...  0.00420516 -0.03917055\n  -0.00120196]\n [-0.03984349  0.01179545 -0.00491921 ... -0.00456766 -0.09548062\n   0.03903243]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nSeq = len(valTokens)\n",
        "maskDims = (nSeq, nSeq)\n",
        "targetMask = t"
      ],
      "metadata": {
        "id": "llnuUcMqDOcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(10) % 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlrOtO9Jvuj4",
        "outputId": "1a5cb772-98eb-425b-8042-c616d9076c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}